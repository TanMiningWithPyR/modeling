---
title: "1.KNN分类"
author: "Affluence Tan"
date: "December 29, 2016"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## 简单理解近邻分类

近邻分类就是把没有标记（标记可以看做是前言里面的对应的函数中的$Y$）的案例归类到与它们最相似（或者说是“相近”）的带有标记的案例所在的类里面。

邻近分类是一种有监督学习。

与之有着藕断丝连的关系的是聚类分析，它是一种无监督学习，我们在下一章讲。

###什么是最近

有很多距离度量，在数学上，一般的说，一个函数$d(x,y)$，如果满足以下四条性质，就可以看做是距离度量：

* $d(x,x)=0$              // 到自己的距离为0   
* $d(x,y)>=0$             // 距离非负  
* $d(x,y)=d(y,x)$         // 对称性: 如果 A 到 B 距离是 a，那么 B 到 A 的距离也应该是 a  
* $d(x,k)+d(k,y)>=d(x,y)$   // 三角形法则: （两边之和大于第三边）  

平时我们遇见最多，也是在中学阶段就领会的一种距离叫做欧几里得距离。二维情况公式形如：$d(x,y)=\sqrt{(x_1-x_2)^{2}+(y_1-y_2)^{2}}$

###什么是K最近

K表示邻居的数量，假设K=3，那么就会在3个邻居中投票表决归属哪一类，3个邻居2个是A类，1个是B类，那么未标记的样本将归为A类。

K的选取关系到模型的是过度拟合还是低度拟合。两种情况我们都应该避免。可以考虑两种极端情况，一个是K取训练数据集的样本量，那么样本量多的标签将永远在投票中获胜。反之，k为1，会使得训练数据集中的异常值过度的影响到未标记的案例。

选取k一般为3~10，或者样本量的平方根。

还有一种有趣的想法是权重投票，该方法认为，比较近邻居的投票比比较远的更有效，所以有更大的权重。

## R实战
### 获取数据集
```{r read dataset}
library(readr)
wbcd <- read_csv("wisc_bc_data.csv")
str(wbcd)
```
wbcd数据集是一个乳腺癌细胞活检的数据集，一共有592个样本和32个变量。顾名思义，diagnosis变量就是细胞是否癌变的诊断。"M"是恶性，"B"是良性的。  

### 探索和准备数据集
```{r explore and prapare data-1}
# drop the id feature
wbcd <- wbcd[-1]

# table of diagnosis
table(wbcd$diagnosis)

# recode diagnosis as a factor
wbcd$diagnosis <- factor(wbcd$diagnosis, levels = c("B", "M"),
                         labels = c("Benign", "Malignant"))

# table or proportions with more informative labels
round(prop.table(table(wbcd$diagnosis)) * 100, digits = 1)
```
一共有良性"B"357个，占总数的67.2%。
```{r explore and prapare data-2}
# summarize three numeric features
summary(wbcd[c("radius_mean", "area_mean", "smoothness_mean")])

# normalize the wbcd data
wbcd_n <- as.data.frame(scale(wbcd[,2:31]))

# confirm that normalization worked
summary(wbcd_n[c("radius_mean", "area_mean", "smoothness_mean")])
```
*由于最后的分类取决于距离计算，仔细一想发现它的结果是依赖于变量的量纲，所以我们要利用scale函数将变量标准化处理* 

接下去可以创建数据集了。

```{r explore and prapare data-3}
# create training and test data
wbcd_train <- wbcd_n[1:469, ]
wbcd_test <- wbcd_n[470:569, ]

# create labels for training and test data

wbcd_train_labels <- wbcd[1:469, 1]
wbcd_test_labels <- wbcd[470:569, 1]
```

数据集本来就是随机的，不需要随机抽取了，直接切分。

### 基于数据集训练模型
```{r training a model on the data}
# load the "class" library
library(class)

wbcd_test_pred <- knn(train = wbcd_train, test = wbcd_test,
                      cl = wbcd_train_labels, k=21)
```

### 评估模型性能

模型性能的评估是一个复杂的话题，它可以单独的成为一个章节。我将在单独的一个章节里面讨论。  
对于一个分类变量，被称为混淆矩阵(confusion matrix)的东西是一个绕不开的话题。

研究一个混淆矩阵的第一步分阴阳。感兴趣的类别为阳性(positive),其他的类别称为阴性。可能你会觉得奇怪，为什么要分阴阳。个人认为，是因为在模型不能同时提高阴性预测率和阳性预测率的情况下，我们要有所取舍。所以不能只看单一的准确度。比如在本案中，人们一般会对癌细胞更加感兴趣。下面用gmodels包中的CrossTable做一下混淆矩阵。

```{r Evaluating model performance}
# load the "gmodels" library
library(gmodels)

# Create the cross tabulation of predicted vs. actual
CrossTable(x = wbcd_test_labels, y = wbcd_test_pred,
           prop.chisq=FALSE)
```

输出表格的第二列(Malignant)为预测阳性，主对角线为预测正确的结果，95%！尽管说我们没有任何医学知识。  
出现了5个假阴性的结果。这种情况下，会出现癌症漏查的结果。假阳性为0，也就是说没有正常人误诊断为癌症。

### 提高模型性能

对于KNN模型来说，我认为有三种方式可能会提升模型性能：  

* 改变距离定义  
* 改变K的取值  
* 改变变量标准化的方法  

这里给出一个改变k值的例子,取k = 1,可以看到出现了2个假阳性的情况。
```{r try k is 1}

wbcd_test_pred <- knn(train = wbcd_train, test = wbcd_test,
                      cl = wbcd_train_labels, k=1)
CrossTable(x = wbcd_test_labels, y = wbcd_test_pred,
           prop.chisq=FALSE)
```
## 小结

一个完整的建模过程一般包含了上面的五个步骤，缺一不可。不同的任务场景，每个步骤的难度也会不一样。
有很多种分类器模型，KNN是最简单的一种，同时也有效。但是我们还是可以看到不足的地方。比如说，模型解释性差（我目前还是不知道该如何评判一个细胞是否是癌细胞），名义变量要进行特殊处理等。